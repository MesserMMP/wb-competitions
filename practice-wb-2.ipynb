{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":430069,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":350581,"modelId":371831}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Импорты","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom datasets import Dataset, DatasetDict, concatenate_datasets\nfrom transformers import (AutoTokenizer, AutoModelForTokenClassification,TrainingArguments,\n    Trainer\n)\n#import Levenshtein as lev\nfrom sklearn.metrics import f1_score\nfrom transformers import DataCollatorForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:09:33.399135Z","iopub.execute_input":"2025-06-15T09:09:33.399486Z","iopub.status.idle":"2025-06-15T09:10:00.586271Z","shell.execute_reply.started":"2025-06-15T09:09:33.399453Z","shell.execute_reply":"2025-06-15T09:10:00.585698Z"}},"outputs":[{"name":"stderr","text":"2025-06-15 09:09:48.074724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749978588.264166      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749978588.320137      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#!pip install Levenshtein","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:02:15.381647Z","iopub.execute_input":"2025-06-11T12:02:15.382392Z","iopub.status.idle":"2025-06-11T12:02:21.189083Z","shell.execute_reply.started":"2025-06-11T12:02:15.382366Z","shell.execute_reply":"2025-06-11T12:02:21.188263Z"}},"outputs":[{"name":"stdout","text":"Collecting Levenshtein\n  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\nSuccessfully installed Levenshtein-0.27.1 rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Загрузка и подготовка данных","metadata":{}},{"cell_type":"code","source":"!mkdir -p ~/.kaggle\n!mv /kaggle/input/kaggle_json/other/default/1/kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:00.587264Z","iopub.execute_input":"2025-06-15T09:10:00.587852Z","iopub.status.idle":"2025-06-15T09:10:01.025739Z","shell.execute_reply.started":"2025-06-15T09:10:00.587831Z","shell.execute_reply":"2025-06-15T09:10:01.024668Z"}},"outputs":[{"name":"stdout","text":"mv: cannot remove '/kaggle/input/kaggle_json/other/default/1/kaggle.json': Read-only file system\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!kaggle competitions download -c ml-dl-practice-level-2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:01.026839Z","iopub.execute_input":"2025-06-15T09:10:01.027110Z","iopub.status.idle":"2025-06-15T09:10:04.476107Z","shell.execute_reply.started":"2025-06-15T09:10:01.027072Z","shell.execute_reply":"2025-06-15T09:10:04.475103Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!unzip -q ml-dl-practice-level-2.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:08.007579Z","iopub.execute_input":"2025-06-15T09:10:08.008418Z","iopub.status.idle":"2025-06-15T09:10:08.629821Z","shell.execute_reply.started":"2025-06-15T09:10:08.008361Z","shell.execute_reply":"2025-06-15T09:10:08.628903Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df = pd.read_csv('train.csv')\ntest_df  = pd.read_csv('test.csv')","metadata":{"id":"m9vLZkMFZ-BU","trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:10.007888Z","iopub.execute_input":"2025-06-15T09:10:10.008808Z","iopub.status.idle":"2025-06-15T09:10:11.287166Z","shell.execute_reply.started":"2025-06-15T09:10:10.008762Z","shell.execute_reply":"2025-06-15T09:10:11.286381Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df[pd.notna(train_df['label'])].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:12.275454Z","iopub.execute_input":"2025-06-15T09:10:12.275747Z","iopub.status.idle":"2025-06-15T09:10:12.313413Z","shell.execute_reply.started":"2025-06-15T09:10:12.275725Z","shell.execute_reply":"2025-06-15T09:10:12.312680Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"    ID                                               text           label\n32  32                                   говно а не товар           говно\n36  36  спасибо за уёбищние шарики!такой хуйни я еще н...  уёбищние,хуйни\n39  39          пришла какая-то х....та вы там чё курите?            х...\n53  53         полное говно, не липнет пустая трата денег           говно\n58  58  на вид очень даже ничего. но хочу сказать, что...            г...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>говно а не товар</td>\n      <td>говно</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>спасибо за уёбищние шарики!такой хуйни я еще н...</td>\n      <td>уёбищние,хуйни</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>пришла какая-то х....та вы там чё курите?</td>\n      <td>х...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>53</td>\n      <td>полное говно, не липнет пустая трата денег</td>\n      <td>говно</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>58</td>\n      <td>на вид очень даже ничего. но хочу сказать, что...</td>\n      <td>г...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_train_short, df_val = train_test_split(train_df, test_size=0.2, random_state=42)\n\n\nds = DatasetDict({\n    \"train\":     Dataset.from_pandas(df_train_short, preserve_index=False),\n    \"validation\":Dataset.from_pandas(df_val,  preserve_index=False),\n    \"test\":      Dataset.from_pandas(test_df, preserve_index=False)\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:15.359647Z","iopub.execute_input":"2025-06-15T09:10:15.359939Z","iopub.status.idle":"2025-06-15T09:10:16.211516Z","shell.execute_reply.started":"2025-06-15T09:10:15.359915Z","shell.execute_reply":"2025-06-15T09:10:16.210602Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model_name = \"deepvk/RuModernBERT-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"id":"GLWj4q6Kgbif","trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:20.913492Z","iopub.execute_input":"2025-06-15T09:10:20.914003Z","iopub.status.idle":"2025-06-15T09:10:24.216988Z","shell.execute_reply.started":"2025-06-15T09:10:20.913980Z","shell.execute_reply":"2025-06-15T09:10:24.216335Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/21.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d403b7bd58b4738bea9aa29c1cce0af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f24d27888fc44ba1a3e5b1f8e9a66b51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/837 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10d3e6441a84059900578f362ceac88"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Функции для преобразования данных под модель","metadata":{}},{"cell_type":"code","source":"def get_spans_from_label(text: str, label_str: str):\n    \"\"\"Из строки меток в формате 'a,b,c' строит список спанов (start,end).\"\"\"\n    if pd.isna(label_str) or label_str.strip() == \"\":\n        return []\n    lower = text.lower()\n    spans = []\n    for w in label_str.split(\",\"):\n        w = w.strip()\n        if not w:\n            continue\n        start = 0\n        while True:\n            idx = lower.find(w, start)\n            if idx < 0:\n                break\n            spans.append((idx, idx + len(w)))\n            start = idx + len(w)\n    return spans\n\ndef decode_spans(offsets, preds):\n    spans, cur = [], None\n    for lab, (s,e) in zip(preds, offsets):\n        if lab == 1:\n            if cur: spans.append(cur)\n            cur = [s,e]\n        elif lab == 2 and cur:\n            cur[1] = e\n        else:\n            if cur:\n                spans.append(cur)\n                cur = None\n    if cur: spans.append(cur)\n    return spans\n\ndef format_str(text, spans):\n    return \",\".join(sorted({ text[s:e].lower() for s,e in spans }))\n\n# Batch-препроцессинг (tokenization + BIO-labels) ===\ndef preprocess_batch(batch):\n    texts = batch[\"text\"]\n    labels_str = batch.get(\"label\", [\"\"])  # для теста label может отсутствовать\n    # 1) для каждого текста строим спаны «золота»\n    spans_list = [get_spans_from_label(t, ls) for t,ls in zip(texts, labels_str)]\n    # 2) батч-токенизация с оффсетами\n    enc = tokenizer(\n        texts,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=256\n    )\n    # 3) строим BIO-метки по оффсетам\n    all_labels = []\n    for offsets, spans in zip(enc[\"offset_mapping\"], spans_list):\n        lab = [0] * len(offsets)\n        for (cs,ce) in spans:\n            began = False\n            for i,(s,e) in enumerate(offsets):\n                if e <= cs or s >= ce:\n                    continue\n                lab[i] = 1 if not began else 2\n                began = True\n        all_labels.append(lab)\n    enc[\"labels\"] = all_labels\n    # 4) удаляем ненужное\n    enc.pop(\"offset_mapping\")\n    return enc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:28.066070Z","iopub.execute_input":"2025-06-15T09:10:28.066380Z","iopub.status.idle":"2025-06-15T09:10:28.076672Z","shell.execute_reply.started":"2025-06-15T09:10:28.066357Z","shell.execute_reply":"2025-06-15T09:10:28.076031Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"ds[\"train\"] = ds[\"train\"].map(\n    preprocess_batch, batched=True, batch_size=2000, remove_columns=[\"ID\", \"text\", \"label\"]\n)\nds[\"validation\"] = ds[\"validation\"].map(\n    preprocess_batch, batched=True, batch_size=2000, remove_columns=[\"ID\", \"text\", \"label\"]\n)\n# Для test: токенизируем без меток\nds[\"test\"] = ds[\"test\"].map(\n    lambda batch: tokenizer(\n        batch[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=256\n    ),\n    batched=True, batch_size=2000, remove_columns=[\"ID\", \"text\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:10:44.741018Z","iopub.execute_input":"2025-06-15T09:10:44.741300Z","iopub.status.idle":"2025-06-15T09:11:55.277117Z","shell.execute_reply.started":"2025-06-15T09:10:44.741279Z","shell.execute_reply":"2025-06-15T09:11:55.276567Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195791 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bd5f1af86c146bb869b094fe6ddc34a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48948 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f3c493a985419baf3b666ed4079302"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/66949 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"268074d11abd4bb7bd621f733633925e"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Объявление модели","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    num_labels=3  # 0=O,1=B,2=I\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:11:57.385003Z","iopub.execute_input":"2025-06-15T09:11:57.386140Z","iopub.status.idle":"2025-06-15T09:12:22.293770Z","shell.execute_reply.started":"2025-06-15T09:11:57.386108Z","shell.execute_reply":"2025-06-15T09:12:22.293029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3566a07f07ec4b3fb5a0cbbcf4f7a5b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8099560f2ba4631b7b236b0925e2519"}},"metadata":{}},{"name":"stderr","text":"Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at deepvk/RuModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n\n    logits, labels = eval_pred\n    preds = logits.argmax(-1)\n\n    f1_macro = f1_score(labels.flatten(), preds.flatten(), average=\"macro\")\n    f1_micro = f1_score(labels.flatten(), preds.flatten(), average=\"micro\")\n\n    return {\n        \"f1_macro\": f1_macro,\n        \"f1_micro\": f1_micro\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:12:53.592584Z","iopub.execute_input":"2025-06-15T09:12:53.593104Z","iopub.status.idle":"2025-06-15T09:12:53.597834Z","shell.execute_reply.started":"2025-06-15T09:12:53.593081Z","shell.execute_reply":"2025-06-15T09:12:53.596999Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Обучение","metadata":{}},{"cell_type":"code","source":"full_train_dataset = concatenate_datasets([ds['train'], ds['validation']])\n\n\nargs = TrainingArguments(\n    save_strategy=\"epoch\",  # save model checkpoints every epoch\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    report_to=\"none\",\n    logging_steps=3750,\n    output_dir=\"RuModernBERT-base-ner\", \n    push_to_hub=True\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=full_train_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:13:12.792839Z","iopub.execute_input":"2025-06-15T09:13:12.793102Z","iopub.status.idle":"2025-06-15T09:13:13.651126Z","shell.execute_reply.started":"2025-06-15T09:13:12.793083Z","shell.execute_reply":"2025-06-15T09:13:13.650600Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:13:16.404096Z","iopub.execute_input":"2025-06-15T09:13:16.404660Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15775' max='22947' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15775/22947 4:36:41 < 2:05:48, 0.95 it/s, Epoch 2.06/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>3750</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>11250</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.000200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.push_to_hub(\"RuModernBERT-base-ner\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Инференс модели","metadata":{}},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    \"/kaggle/working/RuModernBERT-base-ner/checkpoint-15298\",\n    num_labels=3  # 0=O,1=B,2=I\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T16:18:43.418810Z","iopub.execute_input":"2025-06-15T16:18:43.419077Z","iopub.status.idle":"2025-06-15T16:18:43.492566Z","shell.execute_reply.started":"2025-06-15T16:18:43.419058Z","shell.execute_reply":"2025-06-15T16:18:43.491841Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T16:18:58.836897Z","iopub.execute_input":"2025-06-15T16:18:58.837388Z","iopub.status.idle":"2025-06-15T16:19:01.837844Z","shell.execute_reply.started":"2025-06-15T16:18:58.837366Z","shell.execute_reply":"2025-06-15T16:19:01.837303Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"test_df  = pd.read_csv('test.csv')\n# Берём тексты и ID из исходного DataFrame\ntest_texts = test_df[\"text\"].tolist()\ntest_ids   = test_df[\"ID\"].tolist()\n\n# Токенизируем тест с offset_mapping для декодирования спанов\ntest_encodings = tokenizer(\n    test_texts,\n    return_offsets_mapping=True,\n    padding=\"max_length\",\n    truncation=True,\n    max_length=256\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T16:19:05.032909Z","iopub.execute_input":"2025-06-15T16:19:05.033177Z","iopub.status.idle":"2025-06-15T16:19:15.882414Z","shell.execute_reply.started":"2025-06-15T16:19:05.033158Z","shell.execute_reply":"2025-06-15T16:19:15.881769Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Получаем предсказания (логиты → метки) через Trainer\npred_out = trainer.predict(ds[\"test\"])\npred_labels = pred_out.predictions.argmax(axis=-1)  # shape (N, seq_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T16:20:33.490201Z","iopub.execute_input":"2025-06-15T16:20:33.490846Z","iopub.status.idle":"2025-06-15T16:20:33.495258Z","shell.execute_reply.started":"2025-06-15T16:20:33.490814Z","shell.execute_reply":"2025-06-15T16:20:33.494501Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Декодируем спаны и форматируем строку для каждого примера\nresults = []\nfor i, text in enumerate(test_texts):\n    offsets = test_encodings[\"offset_mapping\"][i]        # список (start, end) для каждого токена\n    spans_pred = decode_spans(offsets, pred_labels[i])\n    results.append(format_str(text, spans_pred))        # соберёт, отдублит, сортирует, join\n\n# Собираем DataFrame и сохраняем в submission.csv\nsubmission = pd.DataFrame({\n    \"ID\":    test_ids,\n    \"label\": results\n})\nsubmission.to_csv(\"submission_RuModernBERT-base-ner.csv\", index=False)\nprint(\"✅ Submission saved: submission_RuModernBERT-base-ner.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T16:17:01.202063Z","iopub.execute_input":"2025-06-15T16:17:01.202663Z","iopub.status.idle":"2025-06-15T16:17:04.675752Z","shell.execute_reply.started":"2025-06-15T16:17:01.202635Z","shell.execute_reply":"2025-06-15T16:17:04.675096Z"}},"outputs":[{"name":"stdout","text":"✅ Submission saved: submission_RuModernBERT-base-ner.csv\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import gc\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T19:18:05.833938Z","iopub.execute_input":"2025-06-14T19:18:05.834692Z","iopub.status.idle":"2025-06-14T19:18:06.825188Z","shell.execute_reply.started":"2025-06-14T19:18:05.834667Z","shell.execute_reply":"2025-06-14T19:18:06.824429Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Введите ваш токен API\ntoken = \"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\"\n\n# Вход в Hugging Face Hub\nlogin(token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:13:05.799941Z","iopub.execute_input":"2025-06-15T09:13:05.800438Z","iopub.status.idle":"2025-06-15T09:13:05.998722Z","shell.execute_reply.started":"2025-06-15T09:13:05.800415Z","shell.execute_reply":"2025-06-15T09:13:05.997969Z"}},"outputs":[],"execution_count":13}]}